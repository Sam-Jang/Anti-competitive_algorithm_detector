{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovlpFAQbPpYK",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install bitsandbytes==0.45.0\n",
        "!pip install langchain-community==0.3.13\n",
        "!pip install beautifulsoup4==4.12.3 chromadb==0.5.23 gradio==5.9.1\n",
        "!pip -qq install langchain==0.3.13\n",
        "!pip install sentence-transformers==3.3.1\n",
        "!pip install pymupdf==1.25.1\n",
        "!pip fitz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q7gKz7iUPJ6y"
      },
      "outputs": [],
      "source": [
        "from langchain.chains import LLMChain\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.llms import HuggingFacePipeline\n",
        "from transformers import LlamaForCausalLM, LlamaTokenizer, pipeline\n",
        "import torch\n",
        "from typing import List\n",
        "import gradio as gr\n",
        "import os\n",
        "import pickle\n",
        "from google.colab import userdata\n",
        "from google.colab import drive\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "\n",
        "userdata.get('HF_TOKEN')\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "from transformers import LlamaForCausalLM, AutoTokenizer, pipeline\n",
        "\n",
        "model_path = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = LlamaForCausalLM.from_pretrained(model_path, load_in_8bit=True, device_map=\"auto\")\n",
        "\n",
        "llm_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=4096, do_sample=False)\n",
        "llm = HuggingFacePipeline(pipeline=llm_pipeline)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from google.colab import userdata\n",
        "from google.colab import drive\n",
        "\n",
        "eng_embed = \"BAAI/bge-large-en-v1.5\"\n",
        "\n",
        "embed_model = HuggingFaceEmbeddings(\n",
        "    model_name = eng_embed,\n",
        "    model_kwargs = {'device': 'cpu'},\n",
        "    encode_kwargs = {'normalize_embeddings': True},\n",
        ")"
      ],
      "metadata": {
        "id": "OlBL7x4QYb-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DlJzBxznmQrw"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from bs4 import BeautifulSoup as bs\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "from chromadb.config import Settings\n",
        "\n",
        "localDir = \"/content/drive/MyDrive/Colab Notebooks/RAG_Doc/\"\n",
        "pdf_files = [\n",
        "    {\"file\": \"DOJ_Topkins_ENG.pdf\", \"metadata\": {\"Reason\": \"Price Fixing\", \"Keyword\": \"Algorithmic Pricing\", \"Company\": \"Topkins\", \"year\": \"2015\"}},\n",
        "    {\"file\": \"DOJ_Realpage_ENG.pdf\", \"metadata\": {\"Reason\": \"Price Fixing\", \"Keyword\": \"Algorithmic Pricing\", \"Company\": \"Realpage\", \"year\": \"2024\"}},\n",
        "    {\"file\": \"EU_Google_ENG.pdf\", \"metadata\": {\"Reason\": \"Self Preferencing\", \"Keyword\": \"Search engine\",  \"Company\": \"Google\", \"year\": \"2017\"}},\n",
        "    {\"file\": \"FTC_Amazon_ENG.pdf\", \"metadata\": {\"Reason\": \"Self Preferencing\", \"Keyword\": \"Anti-discounting\",  \"Company\": \"Amazon\", \"year\": \"2023\"}},\n",
        "    {\"file\": \"KFTC_KakaoMobility_ENG.pdf\", \"metadata\": {\"Reason\": \"Self Preferencing\", \"Keyword\": \"Franchise\",  \"Company\": \"Kakao Mobility\", \"year\": \"2023\"}},\n",
        "    {\"file\": \"KFTC_Naver_ENG.pdf\", \"metadata\": {\"Reason\": \"Self Preferencing\", \"Keyword\": \"Search engine\",  \"Company\": \"Naver\", \"year\": \"2020\"}},\n",
        "    {\"file\": \"KFTC_Coupang_ENG.pdf\", \"metadata\": {\"Reason\": \"Self Preferencing\", \"Keyword\": \"Private Label Product / Private Brand Product\",  \"Company\": \"Coupang\", \"year\": \"2020\"}},\n",
        "    {\"file\": \"KFTC_NexonKorea_ENG.pdf\", \"metadata\": {\"Reason\": \"Probability Manipulation\", \"Keyword\": \"Loot box\",  \"Company\": \"Nexon Korea\", \"year\": \"2024\"}}\n",
        "]\n",
        "\n",
        "\n",
        "def read_pdf_with_metadata(file_path, metadata):\n",
        "    loader = PyMuPDFLoader(file_path)\n",
        "    documents = loader.load()\n",
        "\n",
        "    for doc in documents:\n",
        "        doc.metadata = metadata\n",
        "    return documents\n",
        "\n",
        "all_documents=[]\n",
        "\n",
        "for pdf in pdf_files:\n",
        "    pdf_path = os.path.join(localDir, pdf[\"file\"])\n",
        "    docs = read_pdf_with_metadata(pdf_path, pdf[\"metadata\"])\n",
        "    all_documents.extend(docs)\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=3000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(all_documents)\n",
        "\n",
        "\n",
        "DB_PATH = \"/content/drive/MyDrive/Colab Notebooks/ChromaDB_ENG_3000\"\n",
        "\n",
        "vectorstore = Chroma.from_documents(\n",
        "    splits, embedding=embed_model, persist_directory=DB_PATH, collection_name=\"RAG_DB\"\n",
        ")\n",
        "\n",
        "vectorstore.persist()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import Chroma\n",
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "from chromadb.config import Settings\n",
        "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
        "\n",
        "DB_PATH = \"/content/drive/MyDrive/Colab Notebooks/ChromaDB_ENG_3000\"\n",
        "\n",
        "vectorstore = Chroma(\n",
        "    persist_directory=DB_PATH,\n",
        "    embedding_function=embed_model,\n",
        "    collection_name=\"RAG_DB\",\n",
        ")\n",
        "\n",
        "chroma_retriever = vectorstore.as_retriever(search_kwargs = {\n",
        "    \"k\": 20\n",
        "}\n",
        ")"
      ],
      "metadata": {
        "id": "NLV5SxMHQQhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import CrossEncoderReranker\n",
        "from langchain_community.cross_encoders import HuggingFaceCrossEncoder\n",
        "\n",
        "reranker = HuggingFaceCrossEncoder(model_name=\"BAAI/bge-reranker-large\")\n",
        "\n",
        "compressor = CrossEncoderReranker(model=reranker, top_n=20)\n",
        "\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor, base_retriever=chroma_retriever\n",
        ")"
      ],
      "metadata": {
        "id": "AVdkNNMjz33_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_template = \"\"\"\n",
        "<|im_start|>SYSTEM<|im_sep|>\n",
        "You are a helpful assistant working with the competition authority. Your primary responsibility is to analyze source code based solely on the provided instructions and context. Ensure that your analysis is detailed, accurate, and directly linked to the context. Avoid generating assumptions or conclusions not explicitly supported by the provided context and instructions.\n",
        "You only consider competition laws, not personal information laws, security vulnerabilities, or issues unrelated to competition.\n",
        "Specifically, avoid analyzing or commenting on code related to security vulnerabilities or data protection mechanisms.\n",
        "All analysis results must be output as a structured JSON report with detailed explanations and no additional text.\n",
        "\n",
        "Important:\n",
        "1. If the source code depends on external data to determine its legality, clearly state this limitation and set `\"anti-competitive_likelihood\"` to `\"Low\"`.\n",
        "2. Fair randomization algorithms, such as those that equitably and randomly select items with weights, must not be flagged as anti-competitive. Explicitly state that no violations are detected in such cases.\n",
        "\n",
        "<|im_end|>\n",
        "<|im_start|>USER<|im_sep|>\n",
        "The following contexts are part of cases where companies were sanctioned for using anti-competitive algorithms.\n",
        "Context: {context}\n",
        "\n",
        "Note: Use only the provided context for analysis. Do not infer or assume additional information beyond the context provided.\n",
        "\n",
        "Question:\n",
        "# analyze_report is a detailed analysis of the target source code.\n",
        "input_code = {code}\n",
        "\n",
        "def analyze_source_code(input_code: str, context: str) -> dict:\n",
        "\n",
        "    # Step 1: Summarize the source code.\n",
        "    summary = summarize_source_code(input_code)\n",
        "    if not summary:\n",
        "        summary = \"The source code does not provide enough information to determine its functionality.\"\n",
        "\n",
        "    # Step 2: Analyze the code to detect patterns potentially violating competition laws.\n",
        "    suspicious_patterns = detect_patterns(input_code, context)\n",
        "\n",
        "    # Step 3: Exclude certain cases:\n",
        "    explanation = \"\"\n",
        "    if requires_external_data(input_code):\n",
        "        anti_competitive_likelihood = \"Low\"\n",
        "        explanation = \"The source code requires external data to determine its legality.\"\n",
        "    elif is_fair_randomization(input_code):\n",
        "        anti_competitive_likelihood = \"Low\"\n",
        "        explanation = \"The source code implements fair randomization methods, which are not anti-competitive.\"\n",
        "    else:\n",
        "        anti_competitive_likelihood = calculate_violation_probability(suspicious_patterns)\n",
        "\n",
        "    # Step 4: Generate a structured JSON report with detailed explanations for all findings.\n",
        "    result = {{\n",
        "        \"summary\": summary,\n",
        "        \"detected_patterns\": [\n",
        "          {{\n",
        "              \"pattern\": suspicious_patterns.get(\"code_snippet\", \"Not Found\"),\n",
        "              \"similar_case\": suspicious_patterns.get(\"similar_case\", \"Not Found\"),\n",
        "              \"explanation\": explanation\n",
        "          }}\n",
        "        ],\n",
        "        \"anti-competitive_likelihood\": anti_competitive_likelihood\n",
        "    }}\n",
        "\n",
        "    return json.dumps(result, indent=4)\n",
        "\n",
        ">>> analyze_source_code(input_code, context)\n",
        "※ You must print the JSON only.\n",
        "Answer:<|im_end|><|im_start|>assistant<|im_sep|>\n",
        "\"\"\"\n",
        "\n",
        "rag_prompt = PromptTemplate.from_template(rag_template)\n",
        "rag_chain = rag_prompt | llm\n",
        "\n",
        "\n",
        "normal_template = \"\"\"\n",
        "<|begin_of_text|>\n",
        "<|start_header_id|>SYSTEM<|end_header_id|>\n",
        "You are a helpful assistant working with the competition authority. Your task is to verify the validity of an analysis report and provide recommendations for further investigation. Use the provided source code and the first analysis report to:\n",
        "1. Identify any potential hallucinations in the analysis.\n",
        "2. Assess the likelihood of legal violations.\n",
        "3. Recommend additional data that should be collected for a more thorough investigation.\n",
        "\n",
        "Avoid analyzing or commenting on issues related to security vulnerabilities or personal data protection. Focus solely on competition-related concerns.\n",
        "\n",
        "All results must be output as a structured JSON report with detailed explanations and no additional text.\n",
        "If the provided information is insufficient to make a judgment, explicitly state: \"The provided context and source code do not provide enough evidence to determine a violation,\" and set \"violation_possibility\" to \"Low\" in the JSON response.\n",
        "<|eot_id|>\n",
        "<|start_header_id|>USER<|end_header_id|>\n",
        "\n",
        "First_Analysis_Report =\n",
        "{report}\n",
        "\n",
        "input_code =\n",
        "{code}\n",
        "\n",
        "Instructions:\n",
        "def verify_analysis(report: dict, code: str) -> dict:\n",
        "    # Step 1: Verify the validity of the \"detected_patterns\" in the first analysis report.\n",
        "    validation_result = []\n",
        "\n",
        "    for pattern in report.get(\"detected_patterns\", []):\n",
        "        if is_supported_by_code(pattern, code):\n",
        "            # Lower hallucination detection threshold by allowing partial or contextual matches.\n",
        "            if verify_contextual_match(pattern[\"pattern\"], code):\n",
        "                validation_result.append({{\n",
        "                    \"pattern\": pattern[\"pattern\"],\n",
        "                    \"status\": \"Valid\",\n",
        "                    \"similar_case\": pattern.get(\"similar_case\", \"Not Provided\")\n",
        "                }})\n",
        "            else:\n",
        "                validation_result.append({{\n",
        "                    \"pattern\": pattern[\"pattern\"],\n",
        "                    \"status\": \"Invalid\",\n",
        "                    \"similar_case\": \"Not Applicable\"\n",
        "                }})\n",
        "\n",
        "    # Step 2: Assess the likelihood of legal violations based on valid patterns only.\n",
        "    valid_patterns = [p for p in validation_result if p[\"status\"] == \"Valid\"]\n",
        "    if valid_patterns:\n",
        "        anti-competitive_likelihood = reassess_violation(valid_patterns, report[\"anti-competitive_likelihood\"])\n",
        "        # Use only the labels \"High\", \"Low\" and provide a clear justification for the assigned label.\n",
        "    else:\n",
        "        anti-competitive_likelihood = \"Low\"  # Default to \"Low\" if no valid patterns are found.\n",
        "\n",
        "    # Step 3: Recommend additional data to collect.\n",
        "    recommendation_to_collect = recommend_additional_data(valid_patterns)\n",
        "    # Suggest specific data that could provide more evidence for or against the detected patterns.\n",
        "\n",
        "    # Step 4: Generate a structured JSON report with detailed explanations for all findings.\n",
        "    result = {{\n",
        "        \"summary\": generate_summary(report, code),\n",
        "        # Provide a comprehensive but concise summary of the analyze_report’s functionality and its potential anti-competitive implications.\n",
        "\n",
        "        \"detected_patterns\": validation_result,\n",
        "        # Include only valid patterns and their validation status, along with the original similar_case information.\n",
        "\n",
        "        \"anti-competitive_likelihood\": anti-competitive_likelihood,\n",
        "        # \"High\" or \"Low\"\n",
        "\n",
        "        \"recommendation_to_collect\": recommendation_to_collect\n",
        "        # Provide actionable and specific recommendations for further data collection or steps for investigation. Avoid generic suggestions.\n",
        "    }}\n",
        "\n",
        "    return json.dumps(result, indent=4)\n",
        "\n",
        ">>> verify_analysis(First_Analysis_Report, input_code)\n",
        "※ You must print the JSON only.\n",
        "Answer:<|eot_id|><|start_header_id|>ASSISTANT<|end_header_id|>\n",
        "\"\"\"\n",
        "\n",
        "normal_prompt = PromptTemplate.from_template(normal_template)\n",
        "normal_chain = normal_prompt | llm"
      ],
      "metadata": {
        "id": "Qgaxtqqc7l2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(input_code):\n",
        "\n",
        "  docs = compression_retriever.invoke(input_code)\n",
        "  print(\"================================================\")\n",
        "  response1 = rag_chain.invoke({\"context\": docs, \"code\": input_code})\n",
        "  response1_result = response1.split(\"Answer:<|eot_id|><|start_header_id|>ASSISTANT<|end_header_id|>\")[-1].strip()\n",
        "\n",
        "  response2 = normal_chain.invoke({\"report\": response1_result ,\"code\": input_code})\n",
        "  report = response2.split(\"Answer:<|eot_id|><|start_header_id|>ASSISTANT<|end_header_id|>\")[-1].strip()\n",
        "  print(\"================================================\")\n",
        "\n",
        "  return str(report)\n",
        "\n",
        "\n",
        "# Set up Gradio interface\n",
        "def gradio_interface(query):\n",
        "    return predict(query)\n",
        "\n",
        "demo = gr.Interface(fn=gradio_interface, inputs=\"text\", outputs=\"text\", title=\"Anti-Competitive Algorithm Detector\", description=\"Enter a query to check if the source code contains anti-competitive behavior.\")\n",
        "\n",
        "demo.launch()\n"
      ],
      "metadata": {
        "id": "qxLKns6mDkJD"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
